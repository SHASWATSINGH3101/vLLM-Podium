{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d20009b",
   "metadata": {},
   "source": [
    "## Model checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ba0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models in Jan AI:\n",
      "  - Model ID: jan-nano-128k-iQ4_XS.gguf\n",
      "    Object: model\n",
      "    Created: 1751212673\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def check_models():\n",
    "    try:\n",
    "        # Check available models\n",
    "        response = requests.get(\"http://localhost:8080/v1/models\", \n",
    "                              headers={\"Authorization\": \"Bearer qwerty123\"})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            print(\"Available models in Jan AI:\")\n",
    "            if models.get('data'):\n",
    "                for model in models['data']:\n",
    "                    print(f\"  - Model ID: {model.get('id')}\")\n",
    "                    print(f\"    Object: {model.get('object', 'N/A')}\")\n",
    "                    print(f\"    Created: {model.get('created', 'N/A')}\")\n",
    "                    print(\"---\")\n",
    "                return [model['id'] for model in models['data']]\n",
    "            else:\n",
    "                print(\"No models found!\")\n",
    "                return []\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot connect to Jan AI: {e}\")\n",
    "        return []\n",
    "\n",
    "# Get actual model names\n",
    "available_models = check_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951535e",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63635736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Configure LangChain to use your Jan AI server\n",
    "llm = ChatOpenAI(\n",
    "    model=\"Qwen/Qwen3-4B\",  # Replace with your actual model name\n",
    "    openai_api_base=\"https://6d16-104-198-9-125.ngrok-free.app/v1\",\n",
    "    openai_api_key=\"none\",  # Your API key from Jan settings\n",
    "    temperature=0.7,\n",
    "    # max_tokens=512\n",
    ")\n",
    "\n",
    "# Test the connection\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Solve this:- There is a room with a door (closed) and three light bulbs inside the room. Outside the room, there are three switches, connected to the bulbs. You may manipulate the switches as you wish, but once you open the door you can‚Äôt change them. All bulbs are in working condition and you can open the door only once. Identify each switch with respect to its bulb. /no_think\")\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = llm.invoke(messages)\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ce812",
   "metadata": {},
   "source": [
    "## Llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fc0443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hello, World! üåç‚ú®  \n",
      "How can I assist you today? Whether you need help with coding, learning, or anything else, I'm here for you! What would you like to know?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=\"Qwen/Qwen3-4B\",\n",
    "    api_base=\"https://6d16-104-198-9-125.ngrok-free.app/v1\",\n",
    "    api_key=\"qwerty123\",\n",
    "    context_window=128000,\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=True,\n",
    ")\n",
    "\n",
    "response = llm.complete(\"Hello World! /no_think\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9b38a",
   "metadata": {},
   "source": [
    "## Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695697d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 I am Qwen, a large-scale language model developed by Alibaba Cloud. I can answer questions, create content, and assist with various tasks. What can I help you with today?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://4fac-34-31-223-145.ngrok-free.app/v1/chat/completions\"\n",
    "headers = {\"Authorization\": \"Bearer EMPTY\"}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"Menlo/Jan-nano-128k\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"what is your name!\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "resp = requests.post(url, json=payload, headers=headers)\n",
    "print(resp.status_code, resp.json()[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8810edb",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aca0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\n\\n</think>\\n\\nLet\\'s count the number of **\\'r\\'s** in the word **\"blueberries\"**.\\n\\nFirst, write out the word: **b l u e b e r r i e s**\\n\\nNow, let\\'s go through each letter and check for the letter **\\'r\\'**:\\n\\n- b ‚Üí no\\n- l ‚Üí no\\n- u ‚Üí no\\n- e ‚Üí no\\n- b ‚Üí no\\n- e ‚Üí no\\n- r ‚Üí **yes** (1)\\n- r ‚Üí **yes** (2)\\n- i ‚Üí no\\n- e ‚Üí no\\n- s ‚Üí no\\n\\nSo, there are **2** \\'r\\'s in \"blueberries\".\\n\\n**Answer: 2**' additional_kwargs={} response_metadata={'model': 'qwen3:4b', 'created_at': '2025-06-29T16:42:28.6608578Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4274870500, 'load_duration': 131873800, 'prompt_eval_count': 22, 'prompt_eval_duration': 306363200, 'eval_count': 149, 'eval_duration': 3835878700, 'model_name': 'qwen3:4b'} id='run--ff432d47-65b9-42aa-82e1-345adc4fe21a-0' usage_metadata={'input_tokens': 22, 'output_tokens': 149, 'total_tokens': 171}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3:4b\",\n",
    "    # system_prompt=\"/no_think\"\n",
    ")\n",
    "response = llm.invoke(\"Then, how many r's in blueberries? /no_think\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
